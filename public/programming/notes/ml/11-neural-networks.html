<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="/simple.css" />
<meta property="og:title" content="Giovanni's Diary">
<meta property="og:description" content="Diary of Giovanni's adventures.">
<meta property="og:image" content="https://giovanni-diary.netlify.app/logo.png">
<meta property="og:url" content="https://giovanni-diary.netlify.app/">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<p>
<a href="../../../index.html">Giovanni's Diary</a> &gt; <a href="../../../subjects.html">Subjects</a> &gt; <a href="../../programming.html">Programming</a> &gt; <a href="../notes.html">Notes</a> &gt; <a href="intro-to-machine-learning.html">Intro to Machine Learning</a> &gt;
</p>

<div id="outline-container-org7a61276" class="outline-2">
<h2 id="org7a61276">Neural Networks</h2>
<div class="outline-text-2" id="text-org7a61276">
<p>
An artificial neuron, for example a perceptron, is a non-linear
parameterized function with restricted output range. It predicts the
output by learning the weights while considering a bias, more
specifically it associates one weight per input and multiplies them
together.
</p>

<p>
Minsky and Papert (1969) showed that an exclusive OR (XOR) cannot be
solved with a perceptron because the problem is not linearly
separable.
</p>

<p>
This can be solved using <b><b>Multi-Layer perceptron</b></b> where we densely
connect artificial neurons to realize compositions of non-linear
functions. While a single layer perceptron has the form:
</p>

<p>
\[y(x, w)=f ( \sum_{j=1}^M w_j\phi_j(x))\]
</p>

<p>
where \(f(.)\) is a nonlinear activation function in the case of
classification and is the identity in the case of regression. A multi
layer perceptron takes the form:
</p>

<p>
\[y_k(x, w)=\sigma (\sum_{j=1}^M w_{kj}^{(2)}h(\sum_{i=1}^D w_{ji}^{(1)}x_i + w_{j0}^{(1)}) + w_{k0)^{(2)}}\]
</p>

<p>
where \(\sigma (a)\) is something like \(\frac{1}{1+exp(-1)}\) and the
superscript \(w^{(1)}\) indicates that the corresponding parameters are
in the first layer of the network. \(w_{j0}^{(1)}\) are called biases
and \(w_{ji}^{(1)}\) are called weights. \(h(.)\) is a non linear
function. The process of evaluating the previous formula can be
interpreted as forward propagation of information through the
network. We call the layers between the input and the output as
<b><b>hidden</b></b>.
</p>

<p>
Yet we cannot train the MLP like a single perceptron because we cannot
know the desired target for the hidden layers. This problem is solved
by <b><b>backpropagation</b></b>.
</p>
</div>

<div id="outline-container-orgf359dd4" class="outline-3">
<h3 id="orgf359dd4">Task</h3>
<div class="outline-text-3" id="text-orgf359dd4">
<p>
Given training samples \(T=\{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n)
\}\) adjust all the weights of the network \(\Theta\) such that a cost
function is minimized.
</p>

<p>
\[min_{\Theta} \sum _i L(y_i, f(x_i;\Theta))\]
</p>

<p>
We define \(L(.)\) later. We update the weights of each layer with
gradient descent and use backpropagation of the error signal to
compute the gradient efficiently.
</p>
</div>
</div>

<div id="outline-container-org777966a" class="outline-3">
<h3 id="org777966a">Training</h3>
<div class="outline-text-3" id="text-org777966a">
<p>
To train a feed-forward network we need to define:
</p>

<ul class="org-ul">
<li>cost function: we can apply the square loss, for classification is
common to convert output into probabilities with the <b><b>softmax</b></b>
function \(\sigma (z)_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}\)
. Another popular choice is cross entropy \(L_i = -\sum_k y_k
  log(S(l_k)) = -log(S(l))\).</li>
<li>form of output: linear layers \(y=W^Th+b\) produce unnormalized log
probabilities, for this reason It is often used the softmax function
as seed before.</li>
<li>activation functions: we want to apply a non-linear function
element wise. A common one is <b><b>Rectified Linear Units</b></b> (RELU) which
is defined as \(h(x)=max(0, x)\), note that there are variations of
this where the function behaves differently below 0.</li>
<li>architecture (number of layers etc): often done empirically.</li>
<li>optimizer</li>
</ul>
</div>
</div>

<div id="outline-container-org6c55af8" class="outline-3">
<h3 id="org6c55af8">Error Backpropagation</h3>
<div class="outline-text-3" id="text-org6c55af8">
<p>
To learn the weights we use an algorithm called backpropagation, which
is composed of the following steps:
</p>

<ol class="org-ol">
<li><b><b>Feedforward propagation</b></b>: Accept input \(x_i\), pass through
intermediate stages and obtain output</li>
<li>Use the computed output to <b><b>compute a scalar cost</b></b> depending on
the loss function.</li>
</ol>

<p>
\[L(X;w)=\sum_{i=1}^N \frac{1}{2}(y_i-\hat y(x_i;w))^2\]
</p>

<ol class="org-ol">
<li><b><b>Backpropatation</b></b> allows information to flow backwards from cost
to compute the gradient</li>
</ol>

<p>
We will now discuss backpropagation. In a general feed-forward
network, each unit computes a weighted sum of its input of the form:
</p>

<p>
\[a_j=\sum_i w_{ji}z_i\]
</p>

<p>
The sum is then transformed by a non linear activation function
\(h(.)\): \(z_j = h(a_j)\). The error function takes the form:
</p>

<p>
\[E_n=\frac{1}{2}\sum_k (y_{nk}-t_{nk})^2\]
</p>

<p>
The gradient of this error function with respect to a weight \(w_{ji}\)
is given by:
</p>

<p>
\[\frac{\partial E_n}{\partial w_{ji}}=(y_{nj}-t_{nj})x_{ni}\]
</p>

<p>
We note that \(E_n\) depends on the weight \(w_{ji}\) only via the summed
input \(a_j\) to unit \(j\). We can therefore apply the chain rule for
partial derivatives to give:
</p>

<p>
\[\frac{\partial E_n}{\partial w_{ji}}=\frac{\partial E_n}{\partial a_j}\frac{\partial a_j}{\partial w_{ji}}\]
</p>

<p>
We now introduce a useful notation:
</p>

<p>
\[\delta _j \equiv \frac{\partial E_n}{\partial a_j}\]
</p>

<p>
where \(\delta\)'s are often referred to as errors. Using the definition
of \(a_j\) we can write:
</p>

<p>
\[\frac{\partial a_j}{\partial w_{ji}}=z_i\]
</p>

<p>
Substituting the last three equations we obtain:
</p>

<p>
\[\frac{\partial E_n}{\partial w_{ji}}=\delta _jz_i\]
</p>

<p>
For the output units, we have:
</p>

<p>
\[d_k = y_k - t_k\]
</p>

<p>
To evaluate \(\delta\)'s for hidden units, we make use of the chain rule
for partial derivatives:
</p>

<p>
\[\delta _j \equiv \frac{\partial E_n}{\partial a_j}=\sum _k \frac{\partial E_n}{\partial a_k} \frac{\partial a_k}{\partial a_j}\]
</p>

<p>
If we substitute the definition of \(\delta\) and \(a_j\), and make use of
\(h(.)\), we obtain the following <b><b>backpropagation formula</b></b>:
</p>

<p>
\[\delta _j = h'(a_j)\sum _kw_{kj}\delta _k\]
</p>
</div>
</div>

<div id="outline-container-org49c2ebd" class="outline-3">
<h3 id="org49c2ebd">Example</h3>
<div class="outline-text-3" id="text-org49c2ebd">
<p>
Consider a two-layer network (that does not count the input
layer). Given:
</p>

<p>
\[h(a)\equiv tanh(a)\]
\[tanh(a)=\frac{e^a-e^{-a}}{e^a+e^{-a}}\]
\[h'(a)=1-h(a)^2\]
\[E_n = \frac{1}{2}\sum_{k=1}^K (y_k - t_k)^2\]
</p>

<p>
where \(y_k\) is the activation of output unit \(k\), and \(t_k\) is the
corresponding target, for a particular input pattern \(x_n\).
</p>

<p>
For each pattern in the training set in turn, we first perform forward
propagation using:
</p>

<p>
\[a_j = \sum_{i=1}^D w_{ji}^{(1)}x_i\]
\[z_j = tanh(a_j)\]
\[y_k = \sum_{j=1}^M w_{kj}^{(2)}z_j\]
Next we compute the \(\delta\)'s for each output unit using:
</p>

<p>
\[\delta _k = y_k - t_k\]
</p>

<p>
Then we backpropagate there to obtain $&delta;$s for the hidden units
using:
</p>

<p>
\[\delta_j = (1-z_j^2)\sum_{k=1}^K w_{kj}d_k\]
</p>

<p>
Finally, the derivatives with respect to the first-layer and
second-layer weights are given by:
</p>

<p>
\[\frac{\partial E_n}{\partial w_{ji}^{(1)}}=\delta_jx_i,\ \frac{\partial E_n}{\partial w_{kj}^{(2)}}=\delta _kz_j\]
</p>
</div>
</div>

<div id="outline-container-orga359ad4" class="outline-3">
<h3 id="orga359ad4">Optimization</h3>
<div class="outline-text-3" id="text-orga359ad4">
<p>
The function \(f\) is a composition of multiple functions:
</p>

<p>
\[f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x)))\]
</p>

<p>
Feed-forward neural networks can be trained with Vanilla Gradient
Descent, we use backpropagation to compute the gradient efficiently.
</p>

<p>
There are two types of gradient descent:
</p>

<ul class="org-ul">
<li><b><b>Batch Gradient Descent</b></b>: the estimates are stable however you
need to compute gradients over the entire training for one update.</li>
<li><b><b>Stochastic Gradient Descent</b></b>: we sample only one datapoint from
the training set and compute the gradient. The learning rate changes
at each step, It typically decays linearly. A problem arises with
flat error surfaces where the error would jump vividly. We can
introduce a variable called <b><b>velocity</b></b> to counteract this, where
the gradient updates the velocity.</li>
</ul>

<p>
It is often useful to compute the gradient os set of samples
</p>
</div>
</div>

<div id="outline-container-org951eebd" class="outline-3">
<h3 id="org951eebd">Convolutional Neural Networks</h3>
<div class="outline-text-3" id="text-org951eebd">
<p>
Convolutional neural networks are simply neural networks that use
convolution in place of general matrix multiplication in at least one
of their layers.
</p>

<p>
A convolution is a general purpose filter operation for image where a
kernel matrix is applied to an image where the central pixel is
determined by adding the weighted valued of all its neighbors
together, producing a <b><b>feature map</b></b>.
</p>

<p>
\[S(i, j) = (I*K)(i, j) = \sum_m\sum_nI(m, n)K(i-m,j-n)\]
</p>

<p>
Inspired by mammalian visual cortex, convolutional neural networks are
feedforward neural networks with specialized connectivity
structure. In particular, the network is composed of a set of filters
that cover a specially small portion of the input data and that are
convoluted over It. Intuitively, the network will learn filters that
activate when they see some specific type of feature at some spatial
position in the input.
</p>

<p>
After the convolution, it adds non-linearity by applying a non linear
function \(h(.)\). Lastly, It performs spacial pooling which reduces the
spacial size of the representation to reduce the amount of parameters.
</p>
</div>
</div>

<div id="outline-container-orgc189999" class="outline-3">
<h3 id="orgc189999">Other neural networks</h3>
<div class="outline-text-3" id="text-orgc189999">
<ul class="org-ul">
<li>Recurrent network: when nodes on the same layer influence each
other, used in video frame prediction.</li>
<li>Autoencoders: unsupervised approach for learning a lower-dimensional
feature representation from unlabeled training data. We can train a
decoder to do the opposite.</li>
</ul>

<hr />

<p>
Travel: <a href="intro-to-machine-learning.html">Intro to Machine Learning</a>, <a href="../../../theindex.html">Index</a>
</p>
</div>
</div>
</div>
</div>
</body>
</html>
