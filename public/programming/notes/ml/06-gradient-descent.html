<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="/simple.css" />
<meta property="og:title" content="Giovanni's Diary">
<meta property="og:description" content="Diary of Giovanni's adventures.">
<meta property="og:image" content="https://giovanni-diary.netlify.app/logo.png">
<meta property="og:url" content="https://giovanni-diary.netlify.app/">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<p>
<a href="../../../index.html">Giovanni's Diary</a> &gt; <a href="../../../subjects.html">Subjects</a> &gt; <a href="../../programming.html">Programming</a> &gt; <a href="../notes.html">Notes</a> &gt; <a href="intro-to-machine-learning.html">Intro to Machine Learning</a> &gt;
</p>

<div id="outline-container-org9f3583a" class="outline-2">
<h2 id="org9f3583a">Gradient Descent</h2>
<div class="outline-text-2" id="text-org9f3583a">
</div>

<div id="outline-container-orgff67ecc" class="outline-3">
<h3 id="orgff67ecc">Model-Based Machine Learning</h3>
<div class="outline-text-3" id="text-orgff67ecc">
<ol class="org-ol">
<li>Pick a model (hyperplace, decision tree&#x2026;)</li>
<li>Pick a criterion to optimize</li>
<li>Develop a learning algorithm
<ul class="org-ul">
<li>this should try and minimize the criteria, sometimes in a
heuristic way, sometimes exactly</li>
</ul></li>
</ol>

<p>
Let's look at linear binary classification
</p>

<ol class="org-ol">
<li>Pick a model</li>
</ol>
<p>
\[0 = b + \sum_{j=1}^{m}w_jf_j\]
</p>
<ol class="org-ol">
<li>Pick a criteria to optimize (aka objective function)</li>
</ol>
<p>
\[\sum_{i-1}^{n}\mathbb{1}[y_i(w*x_i+b) \le 0]\]
</p>
<ol class="org-ol">
<li>Develop a learning algorithm</li>
</ol>
<p>
\[argmin_{w, b}\sum_{i-1}^{n}\mathbb{1}[y_i(w*x_i+b) \le 0]\]
	Find \(w\) and \(b\) that minimize the 0/1 loss (i.e. training error)
</p>
</div>
</div>

<div id="outline-container-org4335edf" class="outline-3">
<h3 id="org4335edf">Loss Functions</h3>
<div class="outline-text-3" id="text-org4335edf">
<p>
How do we minimize the 0/1 loss? Finding \(w\) and \(b\) that optimize the
0/1 loss is hard (in fact, NP-hard).
</p>

<p>
We want a differentiable (continuous) loss function so we get an
indication of direction of minimization. This family of functions are
called convex functions: the line segment between any two points on
the function is above the function.
</p>

<p>
Therefore, we want to find one such function that represents the 0/1
loss function, which we call <span class="underline">surrogate loss function</span>. There are many
such functions, we use the notation \(y\) as the correct value and \(y'\)
as the predicted value:
</p>

<ul class="org-ul">
<li>0/1 loss: \(l(y, y')=\mathbb{1}[yy' \le 0]\)</li>
<li>Hinge \(l(y, y')= max(0,1-yy')\)</li>
<li>Exponential: \(l(y, y') = exp(-yy')\)</li>
<li>Squared loss: \(l(y, y') = (y -y')^2\)</li>
</ul>
</div>
</div>

<div id="outline-container-org30490ed" class="outline-3">
<h3 id="org30490ed">Gradient Descent</h3>
<div class="outline-text-3" id="text-org30490ed">
<p>
Pick a starting point \(w\). Repeat until loss doesn't decrease in any dimension:
</p>

<ul class="org-ul">
<li>pick a dimension</li>
<li>move a small amount in that dimension towards decreasing loss</li>
</ul>
<p>
\[w_j = w_j - \mu \frac{d}{dw_j}loss\]
</p>
<ul class="org-ul">
<li>\(\mu\) is the learning rate</li>
</ul>

<p>
For example, let's calculate the derivative of the loss function for
the exponential:
</p>

<p>
\[\frac{d}{dw_i} loss = \frac{d}{dw_j} \sum_{i=1}^{n}exp(-y_i(wx_i+b))\]
\[ = \sum_{i=1}^{n}exp(-y_i(wx_i+b))\frac{d}{dw_i}\]
\[= \sum_{i=1}^n -y_ix_{ij}exp(-y_i(wx_i+b))\]
So with the exponential choice of loss function we have the following update rule:
\[w_j = w_j + \mu \sum_{i=1}^n -y_ix_{ij}exp(-y_i(wx_i+b))\]
</p>

<ul class="org-ul">
<li>this may descend to a <span class="underline">local minima</span>.</li>
<li>there may be <span class="underline">saddle points</span> where the gradient is 0 even if we are not in a minimum, where some directions curve upwards and some curve downwards.</li>
</ul>

<p>
There are two types of gradient descent:
</p>

<ul class="org-ul">
<li><span class="underline">Batch Gradient Descent</span>: the estimates are stable however you need to compute gradients over the entire training for one update.</li>
<li><span class="underline">Stochastic Gradient Descent</span>: we sample only one data point from
the training set and compute the gradient. The learning rate changes
at each step, It typically decays linearly. A problem arises with
flat error surfaces where the error would jump vividly. We can
introduce a variable called <span class="underline">velocity</span> to counteract this, where the
gradient updates the velocity.</li>
</ul>

<p>
It is often useful to compute the gradient on set of samples.
</p>
</div>
</div>


<div id="outline-container-org4dfee61" class="outline-3">
<h3 id="org4dfee61">Gradient</h3>
<div class="outline-text-3" id="text-org4dfee61">
<p>
The gradient is the vector of partial derivates w.r.t all the
coordinates of the weights. For \(f: \mathbb{R}^n \rightarrow
\mathbb{R}\) its gradient \(\nabla f:\mathbb{R}^n \rightarrow
\mathbb{R}^n\) is defined at the point \(p=(x_1, ..., x_n)\) in
n-dimensional space as the vector: \[\nabla f(p) =
[\frac{df}{dx_i}(p)\ ...\ \frac{df}{dx_n}(p) ]\] Explained to a
programmer, the gradient is defined for each dimension and It is the
vector where each element is the derivative with respect to that
dimension.  Formally, the gradient of a scalar function \(f(x_1, x_2,
x_3, ..., x_n)\) is denoted \(\nabla f\) where \(\nabla\) is the vector
differential operator (known as del or nabla). The gradient of \(f\) is
defined as the unique vector filed whose dot product with any vector
\(v\) at each point \(x\) is the directional derivative of \(f\) along
\(v\). That is, \[(\nabla f(x))*v = D_vf(x)\] For example, the gradient
of the function \(f(x, y, z)=2x + 3y^2 - sin(z)\) is \(\nabla f(x, y,
z)=[2, 6y, -cos(z)]\) or \(\nabla f(x, y, z)=2i+6yj-cos(z)k\) where \(i\),
\(j\), \(k\) are the standard unit vectors in the direction \(x\), \(y\), \(z\).
</p>

<ul class="org-ul">
<li>Each partial derivative measures how fast the loss changes in one direction</li>
</ul>

<hr />

<p>
Travel: <a href="intro-to-machine-learning.html">Intro to Machine Learning</a>, <a href="../../../theindex.html">Index</a>
</p>
</div>
</div>
</div>
</div>
</body>
</html>
